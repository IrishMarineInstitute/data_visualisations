{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn is a data visualization library built on top of Matplotlib. It is often used because it makes attractive visualizations and works easily with Pandas. While in Matplotlib you often had to write multiple lines of code to create a plot Seaborn makes assumptions on what you want which often translates into getting the same plot with 1 line of code.\n",
    "\n",
    "You can install it using the Anaconda Environment tab, or by executing the following in your terminal pip install seaborn or conda install seaborn.\n",
    "\n",
    "Shift + Tab after attribute to see options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Auto reloads notebook when changes are made\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        station_id                time (UTC)  AtmosphericPressure (millibars)  \\\n",
       "0              M1 2001-02-06 13:00:00+00:00                          967.600   \n",
       "1              M1 2001-02-06 14:00:00+00:00                          969.800   \n",
       "2              M1 2001-02-06 15:00:00+00:00                          972.000   \n",
       "3              M1 2001-02-06 16:00:00+00:00                          973.600   \n",
       "4              M1 2001-02-06 18:00:00+00:00                          976.400   \n",
       "...           ...                       ...                              ...   \n",
       "769620         M3 2022-04-06 13:00:00+00:00                          995.935   \n",
       "769621         M5 2022-04-06 14:00:00+00:00                          992.224   \n",
       "769622         M2 2022-04-06 14:00:00+00:00                          986.963   \n",
       "769623         M3 2022-04-06 14:00:00+00:00                          995.288   \n",
       "769624         M4 2022-04-06 14:00:00+00:00                          977.734   \n",
       "\n",
       "        WindDirection (degrees true)  WindSpeed (knots)  WaveHeight (meters)  \\\n",
       "0                              270.0             21.980                  NaN   \n",
       "1                              270.0             23.930                  NaN   \n",
       "2                              270.0             19.070                  NaN   \n",
       "3                              270.0             15.950                  NaN   \n",
       "4                              270.0             12.060                  NaN   \n",
       "...                              ...                ...                  ...   \n",
       "769620                         264.0             27.779                4.141   \n",
       "769621                         236.0             21.973                2.734   \n",
       "769622                         222.0             17.760                1.406   \n",
       "769623                         268.0             30.739                3.984   \n",
       "769624                         244.0             29.600                5.781   \n",
       "\n",
       "        WavePeriod (seconds)  SeaTemperature (degrees_C)  \\\n",
       "0                        NaN                       9.000   \n",
       "1                        NaN                       9.000   \n",
       "2                        NaN                       9.000   \n",
       "3                        NaN                       9.000   \n",
       "4                        NaN                       9.000   \n",
       "...                      ...                         ...   \n",
       "769620                 7.266                      11.261   \n",
       "769621                 5.742                       9.954   \n",
       "769622                 4.219                       9.179   \n",
       "769623                 6.914                      11.252   \n",
       "769624                 7.969                      10.413   \n",
       "\n",
       "        salinity (dimensionless)  year  month  day  mean_yr_station  \\\n",
       "0                            NaN  2001      2    6        12.788569   \n",
       "1                            NaN  2001      2    6        12.788569   \n",
       "2                            NaN  2001      2    6        12.788569   \n",
       "3                            NaN  2001      2    6        12.788569   \n",
       "4                            NaN  2001      2    6        12.788569   \n",
       "...                          ...   ...    ...  ...              ...   \n",
       "769620                       NaN  2022      4    6        11.182745   \n",
       "769621                       NaN  2022      4    6         9.961964   \n",
       "769622                      25.0  2022      4    6         8.964279   \n",
       "769623                       NaN  2022      4    6        11.182745   \n",
       "769624                       NaN  2022      4    6        10.440115   \n",
       "\n",
       "        min_yr_station  max_yr_station months  \n",
       "0                8.900          16.500    Feb  \n",
       "1                8.900          16.500    Feb  \n",
       "2                8.900          16.500    Feb  \n",
       "3                8.900          16.500    Feb  \n",
       "4                8.900          16.500    Feb  \n",
       "...                ...             ...    ...  \n",
       "769620          10.754          12.365    Apr  \n",
       "769621           9.223          10.995    Apr  \n",
       "769622           8.522           9.765    Apr  \n",
       "769623          10.754          12.365    Apr  \n",
       "769624           9.785          11.202    Apr  \n",
       "\n",
       "[769625 rows x 16 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IWB temp data from online source\n",
    "weatherbuoy_df = pd.read_csv('https://erddap.marine.ie/erddap/tabledap/IWBNetwork.csvp?station_id%2Ctime%2CAtmosphericPressure%2CWindDirection%2CWindSpeed%2CWaveHeight%2CWavePeriod%2CSeaTemperature%2Csalinity')\n",
    "\n",
    "# from local source\n",
    "# weatherbuoy_df = pd.read_csv('data\\IWBNetwork_archive.csv')\n",
    "weatherbuoy_df['time (UTC)'] = pd.to_datetime(weatherbuoy_df['time (UTC)'])\n",
    "weatherbuoy_df['year'] = weatherbuoy_df['time (UTC)'].dt.year\n",
    "weatherbuoy_df['month'] = weatherbuoy_df['time (UTC)'].dt.month\n",
    "weatherbuoy_df['day'] = weatherbuoy_df['time (UTC)'].dt.day\n",
    "weatherbuoy_df['mean_yr_station'] = weatherbuoy_df.groupby(['year', 'station_id'])[\n",
    "    \"SeaTemperature (degrees_C)\"].transform('mean')\n",
    "weatherbuoy_df['min_yr_station'] = weatherbuoy_df.groupby(['year', 'station_id'])[\n",
    "    \"SeaTemperature (degrees_C)\"].transform('min')\n",
    "weatherbuoy_df['max_yr_station'] = weatherbuoy_df.groupby(['year', 'station_id'])[\n",
    "    \"SeaTemperature (degrees_C)\"].transform('max')\n",
    "# convert number months to the text months for easier display\n",
    "weatherbuoy_df['months'] = weatherbuoy_df['time (UTC)'].dt.strftime('%b')\n",
    "\n",
    "weatherbuoy_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Year  Quarter ICES_Area Gear_Code           Scientific_Name  \\\n",
       "0      1960        1    27.7.g   Unknown           Clupea harengus   \n",
       "1      1960        4    27.7.a       PTM           Clupea harengus   \n",
       "2      1960        4    27.7.a   Unknown           Clupea harengus   \n",
       "3      1961        4    27.7.a   Unknown           Clupea harengus   \n",
       "4      1961        4    27.7.b   Unknown           Clupea harengus   \n",
       "...     ...      ...       ...       ...                       ...   \n",
       "35278  2019        3    27.7.j       TWR  Melanogrammus aeglefinus   \n",
       "35279  2019        3    27.7.j       TWR     Pleuronectes platessa   \n",
       "35280  2019        3    27.7.j       TWR               Solea solea   \n",
       "35281  2019        3    27.7.j       TWR         Lophius budegassa   \n",
       "35282  2019        3    27.7.j       TWR      Merlangius merlangus   \n",
       "\n",
       "               Common_Name   AphiaID  Demersal_At_Sea_Scheme_Age_Observations  \\\n",
       "0         Atlantic Herring  126417.0                                        0   \n",
       "1         Atlantic Herring  126417.0                                        0   \n",
       "2         Atlantic Herring  126417.0                                        0   \n",
       "3         Atlantic Herring  126417.0                                        0   \n",
       "4         Atlantic Herring  126417.0                                        0   \n",
       "...                    ...       ...                                      ...   \n",
       "35278              Haddock  126437.0                                        0   \n",
       "35279      European Plaice  127143.0                                        0   \n",
       "35280          Common Sole  127160.0                                        0   \n",
       "35281  Blackbellied Angler  126554.0                                        0   \n",
       "35282              Whiting  126438.0                                        0   \n",
       "\n",
       "       Demersal_At_Sea_Scheme_Biological_Observations  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "35278                                               0   \n",
       "35279                                               0   \n",
       "35280                                               0   \n",
       "35281                                               0   \n",
       "35282                                               0   \n",
       "\n",
       "       Demersal_At_Sea_Scheme_Length_Observations  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "35278                                           0   \n",
       "35279                                           0   \n",
       "35280                                           0   \n",
       "35281                                           0   \n",
       "35282                                           0   \n",
       "\n",
       "       Pelagic_At_Sea_Scheme_Age_Observations  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "35278                                       0   \n",
       "35279                                       0   \n",
       "35280                                       0   \n",
       "35281                                       0   \n",
       "35282                                       0   \n",
       "\n",
       "       Pelagic_At_Sea_Scheme_Biological_Observations  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "35278                                              0   \n",
       "35279                                              0   \n",
       "35280                                              0   \n",
       "35281                                              0   \n",
       "35282                                              0   \n",
       "\n",
       "       Pelagic_At_Sea_Scheme_Length_Observations  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "35278                                          0   \n",
       "35279                                          0   \n",
       "35280                                          0   \n",
       "35281                                          0   \n",
       "35282                                          0   \n",
       "\n",
       "       Nephrops_At_Sea_Scheme_Age_Observations  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "35278                                        0   \n",
       "35279                                        0   \n",
       "35280                                        0   \n",
       "35281                                        0   \n",
       "35282                                        0   \n",
       "\n",
       "       Nephrops_At_Sea_Scheme_Biological_Observations  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "35278                                               0   \n",
       "35279                                               0   \n",
       "35280                                               0   \n",
       "35281                                               0   \n",
       "35282                                               0   \n",
       "\n",
       "       Nephrops_At_Sea_Scheme_Length_Observations  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "35278                                           0   \n",
       "35279                                           0   \n",
       "35280                                           0   \n",
       "35281                                           0   \n",
       "35282                                           0   \n",
       "\n",
       "       Port_Sampling_Scheme_Age_Observations  \\\n",
       "0                                         99   \n",
       "1                                         73   \n",
       "2                                         86   \n",
       "3                                         50   \n",
       "4                                         77   \n",
       "...                                      ...   \n",
       "35278                                      0   \n",
       "35279                                      0   \n",
       "35280                                      0   \n",
       "35281                                      0   \n",
       "35282                                      0   \n",
       "\n",
       "       Port_Sampling_Scheme_Biological_Observations  \\\n",
       "0                                                99   \n",
       "1                                                73   \n",
       "2                                                86   \n",
       "3                                                50   \n",
       "4                                                77   \n",
       "...                                             ...   \n",
       "35278                                            34   \n",
       "35279                                            70   \n",
       "35280                                            26   \n",
       "35281                                            13   \n",
       "35282                                            15   \n",
       "\n",
       "       Port_Sampling_Scheme_Length_Observations  \n",
       "0                                           150  \n",
       "1                                            78  \n",
       "2                                            90  \n",
       "3                                            50  \n",
       "4                                            75  \n",
       "...                                         ...  \n",
       "35278                                        82  \n",
       "35279                                       202  \n",
       "35280                                       136  \n",
       "35281                                        33  \n",
       "35282                                       123  \n",
       "\n",
       "[35283 rows x 19 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IGFS Published Data\n",
    "igfs_df = pd.read_csv('https://erddap.marine.ie/erddap/tabledap/imi_feas_obs_sp.csvp?Year%2CQuarter%2CICES_Area%2CGear_Code%2CScientific_Name%2CCommon_Name%2CAphiaID%2CDemersal_At_Sea_Scheme_Age_Observations%2CDemersal_At_Sea_Scheme_Biological_Observations%2CDemersal_At_Sea_Scheme_Length_Observations%2CPelagic_At_Sea_Scheme_Age_Observations%2CPelagic_At_Sea_Scheme_Biological_Observations%2CPelagic_At_Sea_Scheme_Length_Observations%2CNephrops_At_Sea_Scheme_Age_Observations%2CNephrops_At_Sea_Scheme_Biological_Observations%2CNephrops_At_Sea_Scheme_Length_Observations%2CPort_Sampling_Scheme_Age_Observations%2CPort_Sampling_Scheme_Biological_Observations%2CPort_Sampling_Scheme_Length_Observations')\n",
    "igfs_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time (UTC)</th>\n",
       "      <th>longitude (degrees_east)</th>\n",
       "      <th>latitude (degrees_north)</th>\n",
       "      <th>stationID</th>\n",
       "      <th>Water_Level (metres)</th>\n",
       "      <th>Water_Level_ODM (metres)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_yr_station</th>\n",
       "      <th>min_yr_station</th>\n",
       "      <th>max_yr_station</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.588278</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:05:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.588278</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 00:10:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.588278</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 00:15:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.588278</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 00:20:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>2.65</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.588278</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315644</th>\n",
       "      <td>2024-12-31 23:40:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.589858</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.86</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315645</th>\n",
       "      <td>2024-12-31 23:45:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.589858</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.86</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315646</th>\n",
       "      <td>2024-12-31 23:50:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.589858</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.86</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315647</th>\n",
       "      <td>2024-12-31 23:55:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.589858</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.86</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315648</th>\n",
       "      <td>2025-01-01 00:00:00+00:00</td>\n",
       "      <td>-6.0683</td>\n",
       "      <td>53.39148</td>\n",
       "      <td>Howth</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315649 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time (UTC)  longitude (degrees_east)  \\\n",
       "0      2022-01-01 00:00:00+00:00                   -6.0683   \n",
       "1      2022-01-01 00:05:00+00:00                   -6.0683   \n",
       "2      2022-01-01 00:10:00+00:00                   -6.0683   \n",
       "3      2022-01-01 00:15:00+00:00                   -6.0683   \n",
       "4      2022-01-01 00:20:00+00:00                   -6.0683   \n",
       "...                          ...                       ...   \n",
       "315644 2024-12-31 23:40:00+00:00                   -6.0683   \n",
       "315645 2024-12-31 23:45:00+00:00                   -6.0683   \n",
       "315646 2024-12-31 23:50:00+00:00                   -6.0683   \n",
       "315647 2024-12-31 23:55:00+00:00                   -6.0683   \n",
       "315648 2025-01-01 00:00:00+00:00                   -6.0683   \n",
       "\n",
       "        latitude (degrees_north) stationID  Water_Level (metres)  \\\n",
       "0                       53.39148     Howth                  2.95   \n",
       "1                       53.39148     Howth                  2.87   \n",
       "2                       53.39148     Howth                  2.80   \n",
       "3                       53.39148     Howth                  2.72   \n",
       "4                       53.39148     Howth                  2.65   \n",
       "...                          ...       ...                   ...   \n",
       "315644                  53.39148     Howth                  4.01   \n",
       "315645                  53.39148     Howth                  4.03   \n",
       "315646                  53.39148     Howth                  4.04   \n",
       "315647                  53.39148     Howth                  4.05   \n",
       "315648                  53.39148     Howth                  4.05   \n",
       "\n",
       "        Water_Level_ODM (metres)  year  month  day  mean_yr_station  \\\n",
       "0                           0.27  2022      1    1         2.588278   \n",
       "1                           0.19  2022      1    1         2.588278   \n",
       "2                           0.12  2022      1    1         2.588278   \n",
       "3                           0.04  2022      1    1         2.588278   \n",
       "4                          -0.03  2022      1    1         2.588278   \n",
       "...                          ...   ...    ...  ...              ...   \n",
       "315644                      1.33  2024     12   31         2.589858   \n",
       "315645                      1.35  2024     12   31         2.589858   \n",
       "315646                      1.36  2024     12   31         2.589858   \n",
       "315647                      1.37  2024     12   31         2.589858   \n",
       "315648                      1.37  2025      1    1         4.050000   \n",
       "\n",
       "        min_yr_station  max_yr_station months  \n",
       "0                 0.26            4.78    Jan  \n",
       "1                 0.26            4.78    Jan  \n",
       "2                 0.26            4.78    Jan  \n",
       "3                 0.26            4.78    Jan  \n",
       "4                 0.26            4.78    Jan  \n",
       "...                ...             ...    ...  \n",
       "315644            0.04            4.86    Dec  \n",
       "315645            0.04            4.86    Dec  \n",
       "315646            0.04            4.86    Dec  \n",
       "315647            0.04            4.86    Dec  \n",
       "315648            4.05            4.05    Jan  \n",
       "\n",
       "[315649 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tide Prediction Data\n",
    "# Howth\n",
    "tide_pred_df = pd.read_csv('https://erddap.marine.ie/erddap/tabledap/IMI-TidePrediction.csvp?time%2Clongitude%2Clatitude%2CstationID%2CWater_Level%2CWater_Level_ODM&time%3E=2022-01-01&time%3C=2025-01-01T00%3A20%3A00Z&stationID=%22Howth%22')\n",
    "\n",
    "tide_pred_df['time (UTC)'] = pd.to_datetime(tide_pred_df['time (UTC)'])\n",
    "tide_pred_df['year'] = tide_pred_df['time (UTC)'].dt.year\n",
    "tide_pred_df['month'] = tide_pred_df['time (UTC)'].dt.month\n",
    "tide_pred_df['day'] = tide_pred_df['time (UTC)'].dt.day\n",
    "tide_pred_df['mean_yr_station'] = tide_pred_df.groupby(['year', 'stationID'])[\n",
    "    \"Water_Level (metres)\"].transform('mean')\n",
    "tide_pred_df['min_yr_station'] = tide_pred_df.groupby(['year', 'stationID'])[\n",
    "    \"Water_Level (metres)\"].transform('min')\n",
    "tide_pred_df['max_yr_station'] = tide_pred_df.groupby(['year', 'stationID'])[\n",
    "    \"Water_Level (metres)\"].transform('max')\n",
    "# convert number months to the text months for easier display\n",
    "tide_pred_df['months'] = tide_pred_df['time (UTC)'].dt.strftime('%b')\n",
    "tide_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time (UTC)</th>\n",
       "      <th>station_id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>PeakPeriod (s)</th>\n",
       "      <th>PeakDirection (degrees_true)</th>\n",
       "      <th>UpcrossPeriod (s)</th>\n",
       "      <th>SignificantWaveHeight (cm)</th>\n",
       "      <th>SeaTemperature (degree_C)</th>\n",
       "      <th>Hmax (cm)</th>\n",
       "      <th>THmax (s)</th>\n",
       "      <th>MeanCurDirTo (degrees_true)</th>\n",
       "      <th>MeanCurSpeed (m/s)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01 00:00:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.833</td>\n",
       "      <td>313.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01 00:03:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.817</td>\n",
       "      <td>317.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-01 00:07:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.838</td>\n",
       "      <td>322.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01 00:10:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.848</td>\n",
       "      <td>321.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01 00:13:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>11.11</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.776</td>\n",
       "      <td>319.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146517</th>\n",
       "      <td>2022-03-30 23:47:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>8.33</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6.198</td>\n",
       "      <td>278.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146518</th>\n",
       "      <td>2022-03-30 23:50:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>8.33</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6.199</td>\n",
       "      <td>276.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146519</th>\n",
       "      <td>2022-03-30 23:53:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.299</td>\n",
       "      <td>288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146520</th>\n",
       "      <td>2022-03-30 23:57:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.301</td>\n",
       "      <td>288.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146521</th>\n",
       "      <td>2022-03-31 00:00:00+00:00</td>\n",
       "      <td>AMETS Berth A Wave Buoy</td>\n",
       "      <td>Datawell WaveRider MkIII</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.265</td>\n",
       "      <td>285.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146522 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time (UTC)               station_id  \\\n",
       "0      2021-04-01 00:00:00+00:00  AMETS Berth A Wave Buoy   \n",
       "1      2021-04-01 00:03:00+00:00  AMETS Berth A Wave Buoy   \n",
       "2      2021-04-01 00:07:00+00:00  AMETS Berth A Wave Buoy   \n",
       "3      2021-04-01 00:10:00+00:00  AMETS Berth A Wave Buoy   \n",
       "4      2021-04-01 00:13:00+00:00  AMETS Berth A Wave Buoy   \n",
       "...                          ...                      ...   \n",
       "146517 2022-03-30 23:47:00+00:00  AMETS Berth A Wave Buoy   \n",
       "146518 2022-03-30 23:50:00+00:00  AMETS Berth A Wave Buoy   \n",
       "146519 2022-03-30 23:53:00+00:00  AMETS Berth A Wave Buoy   \n",
       "146520 2022-03-30 23:57:00+00:00  AMETS Berth A Wave Buoy   \n",
       "146521 2022-03-31 00:00:00+00:00  AMETS Berth A Wave Buoy   \n",
       "\n",
       "                      instrument  PeakPeriod (s)  \\\n",
       "0       Datawell WaveRider MkIII           10.00   \n",
       "1       Datawell WaveRider MkIII           10.00   \n",
       "2       Datawell WaveRider MkIII           10.00   \n",
       "3       Datawell WaveRider MkIII           10.00   \n",
       "4       Datawell WaveRider MkIII           11.11   \n",
       "...                          ...             ...   \n",
       "146517  Datawell WaveRider MkIII            8.33   \n",
       "146518  Datawell WaveRider MkIII            8.33   \n",
       "146519  Datawell WaveRider MkIII            8.00   \n",
       "146520  Datawell WaveRider MkIII            8.00   \n",
       "146521  Datawell WaveRider MkIII            8.00   \n",
       "\n",
       "        PeakDirection (degrees_true)  UpcrossPeriod (s)  \\\n",
       "0                                6.3              7.833   \n",
       "1                                5.6              7.817   \n",
       "2                               12.8              7.838   \n",
       "3                               12.3              7.848   \n",
       "4                                8.6              7.776   \n",
       "...                              ...                ...   \n",
       "146517                          10.3              6.198   \n",
       "146518                          12.4              6.199   \n",
       "146519                          11.0              6.299   \n",
       "146520                          10.1              6.301   \n",
       "146521                           9.3              6.265   \n",
       "\n",
       "        SignificantWaveHeight (cm)  SeaTemperature (degree_C)  Hmax (cm)  \\\n",
       "0                            313.3                        NaN      491.0   \n",
       "1                            317.6                        NaN        NaN   \n",
       "2                            322.7                        NaN        NaN   \n",
       "3                            321.7                        NaN        NaN   \n",
       "4                            319.3                        NaN        NaN   \n",
       "...                            ...                        ...        ...   \n",
       "146517                       278.8                        NaN        NaN   \n",
       "146518                       276.8                        NaN        NaN   \n",
       "146519                       288.0                        NaN        NaN   \n",
       "146520                       288.9                        NaN        NaN   \n",
       "146521                       285.1                        NaN      438.0   \n",
       "\n",
       "        THmax (s)  MeanCurDirTo (degrees_true)  MeanCurSpeed (m/s)  year  \\\n",
       "0           10.01                          NaN                 NaN  2021   \n",
       "1             NaN                          NaN                 NaN  2021   \n",
       "2             NaN                          NaN                 NaN  2021   \n",
       "3             NaN                          NaN                 NaN  2021   \n",
       "4             NaN                          NaN                 NaN  2021   \n",
       "...           ...                          ...                 ...   ...   \n",
       "146517        NaN                          NaN                 NaN  2022   \n",
       "146518        NaN                          NaN                 NaN  2022   \n",
       "146519        NaN                          NaN                 NaN  2022   \n",
       "146520        NaN                          NaN                 NaN  2022   \n",
       "146521       8.27                          NaN                 NaN  2022   \n",
       "\n",
       "        month  day months  \n",
       "0           4    1    Apr  \n",
       "1           4    1    Apr  \n",
       "2           4    1    Apr  \n",
       "3           4    1    Apr  \n",
       "4           4    1    Apr  \n",
       "...       ...  ...    ...  \n",
       "146517      3   30    Mar  \n",
       "146518      3   30    Mar  \n",
       "146519      3   30    Mar  \n",
       "146520      3   30    Mar  \n",
       "146521      3   31    Mar  \n",
       "\n",
       "[146522 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wave Buoy Data\n",
    "# AMETS Berth A 2021/2\n",
    "wave_df = pd.read_csv('https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork.csvp?time%2Cstation_id%2Cinstrument%2CPeakPeriod%2CPeakDirection%2CUpcrossPeriod%2CSignificantWaveHeight%2CSeaTemperature%2CHmax%2CTHmax%2CMeanCurDirTo%2CMeanCurSpeed&time%3E=2021-04-01&time%3C=2022-03-31&station_id=%22AMETS%20Berth%20A%20Wave%20Buoy%22')\n",
    "\n",
    "wave_df['time (UTC)'] = pd.to_datetime(wave_df['time (UTC)'])\n",
    "wave_df['year'] = wave_df['time (UTC)'].dt.year\n",
    "wave_df['month'] = wave_df['time (UTC)'].dt.month\n",
    "wave_df['day'] = wave_df['time (UTC)'].dt.day\n",
    "\n",
    "# convert number months to the text months for easier display\n",
    "wave_df['months'] = wave_df['time (UTC)'].dt.strftime('%b')\n",
    "wave_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified data - one station\n",
    "# m2 = Irish Sea\n",
    "m2_df = weatherbuoy_df[(weatherbuoy_df.station_id == 'M2')]\n",
    "# m5 = Celtic Sea\n",
    "m5_df = weatherbuoy_df[(weatherbuoy_df.station_id == 'M5')]\n",
    "# m6 = Mid Atlantic\n",
    "m6_df = weatherbuoy_df[(weatherbuoy_df.station_id == 'M6')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Elevation Profile Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-65e8b7b3efe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# You can import custom data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0melevation_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/Elevation Profile Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Elevation Profile Data.csv'"
     ]
    }
   ],
   "source": [
    "# You can import custom data\n",
    "elevation_df = pd.read_csv('./data/Elevation Profile Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot of Continental Shelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "sns.set(rc={'axes.facecolor':'black', 'figure.facecolor':'white', \"grid.color\": \"black\"})\n",
    "shelf_plot = sns.barplot(x='Distance', y='Elevation', data=elevation_df, linewidth=0, dodge=False)\n",
    "# sns.histplot(x='Distance', y='Elevation', data=elevation_df, linewidth=0)#, dodge=False)\n",
    "shelf_plot.set_title(\"Ireland's Continental Shelf Depth Profile\", fontsize=20)\n",
    "shelf_plot.set(xticklabels=[])\n",
    "shelf_plot.set(xlabel=None)\n",
    "shelf_plot.set_ylabel(\"Depth (m)\", fontsize=14)\n",
    "shelf_plot.set_yticklabels(labels=[-5000, -4000, -3000, -2000, -1000, 0], fontsize=14)\n",
    "plt.savefig('continental_shelf_depth_profile.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rose Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import plotly.express as px\n",
    "df = px.data.wind()\n",
    "\n",
    "bins_dir = [0, 11.25, 33.75, 56.25, 78.75,101.25,123.75,146.25,168.75,191.25,213.75,236.25,258.75,281.25,303.75,326.25,348.75, 360.00]\n",
    "bins_dir_labels = ['N','NNE','NE','ENE','E','ESE','SE','SSE','S','SSW','SW','WSW','W','WNW','NW','NNW','North']\n",
    "\n",
    "m5_df['Wind Speed Category (knots)'] = pd.cut(m5_df['WindSpeed (knots)'], bins=[0, 4, 8, 12, 16, 20, 24, 1000], include_lowest=True, \n",
    "                                    labels=['4-8', '8-12', '12-16', '16-20', '20-24', '24-28', '28+'])\n",
    "m5_df['dir_binned'] = pd.cut(m5_df['WindDirection (degrees true)'],bins_dir, labels=bins_dir_labels)\n",
    "\n",
    "dfe = m5_df[['Wind Speed Category (knots)', 'dir_binned']].copy() #here i am creating a new dataframe, with necessary columns only (except the last one, which I will convert to frequencies column\n",
    "\n",
    "g = dfe.groupby(['Wind Speed Category (knots)','dir_binned']).size()\\\n",
    "        .reset_index(name=\"frequency\") #grouping\n",
    "g.reset_index(inplace=True) \n",
    "g['percentage'] = g['frequency']/g['frequency'].sum()\n",
    "g['percentage%'] = g['percentage']*100\n",
    "g = g.replace(r'North', 'N', regex=True)\n",
    "\n",
    "fig = px.bar_polar(g, r=\"percentage%\", theta=\"dir_binned\",\n",
    "                   color=\"Wind Speed Category (knots)\", template=\"plotly_dark\",\n",
    "                   color_discrete_sequence= px.colors.sequential.Plasma_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import plotly.express as px\n",
    "df = px.data.wind()\n",
    "\n",
    "bins_dir = [0, 11.25, 33.75, 56.25, 78.75,101.25,123.75,146.25,168.75,191.25,213.75,236.25,258.75,281.25,303.75,326.25,348.75, 360.00]\n",
    "bins_dir_labels = ['N','NNE','NE','ENE','E','ESE','SE','SSE','S','SSW','SW','WSW','W','WNW','NW','NNW','North']\n",
    "\n",
    "m2_df['Wind Speed Category (knots)'] = pd.cut(m2_df['WindSpeed (knots)'], bins=[0, 4, 8, 12, 16, 20, 24, 1000], include_lowest=True, \n",
    "                                    labels=['4-8', '8-12', '12-16', '16-20', '20-24', '24-28', '28+'])\n",
    "m2_df['dir_binned'] = pd.cut(m2_df['WindDirection (degrees true)'],bins_dir, labels=bins_dir_labels)\n",
    "\n",
    "dfe = m2_df[['Wind Speed Category (knots)', 'dir_binned']].copy() #here i am creating a new dataframe, with necessary columns only (except the last one, which I will convert to frequencies column\n",
    "\n",
    "g = dfe.groupby(['Wind Speed Category (knots)','dir_binned']).size()\\\n",
    "        .reset_index(name=\"frequency\") #grouping\n",
    "g.reset_index(inplace=True) \n",
    "g['percentage'] = g['frequency']/g['frequency'].sum()\n",
    "g['percentage%'] = g['percentage']*100\n",
    "g = g.replace(r'North', 'N', regex=True)\n",
    "\n",
    "fig = px.bar_polar(g, r=\"percentage%\", theta=\"dir_binned\",\n",
    "                   color=\"Wind Speed Category (knots)\", template=\"plotly_dark\",\n",
    "                   color_discrete_sequence= px.colors.sequential.Plasma_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import plotly.express as px\n",
    "df = px.data.wind()\n",
    "\n",
    "bins_dir = [0, 11.25, 33.75, 56.25, 78.75,101.25,123.75,146.25,168.75,191.25,213.75,236.25,258.75,281.25,303.75,326.25,348.75, 360.00]\n",
    "bins_dir_labels = ['N','NNE','NE','ENE','E','ESE','SE','SSE','S','SSW','SW','WSW','W','WNW','NW','NNW','North']\n",
    "\n",
    "m6_df['Wind Speed Category (knots)'] = pd.cut(m6_df['WindSpeed (knots)'], bins=[0, 4, 8, 12, 16, 20, 24, 1000], include_lowest=True, \n",
    "                                    labels=['4-8', '8-12', '12-16', '16-20', '20-24', '24-28', '36+'])\n",
    "m6_df['dir_binned'] = pd.cut(m6_df['WindDirection (degrees true)'],bins_dir, labels=bins_dir_labels)\n",
    "\n",
    "dfe = m6_df[['Wind Speed Category (knots)', 'dir_binned']].copy() #here i am creating a new dataframe, with necessary columns only (except the last one, which I will convert to frequencies column\n",
    "\n",
    "g = dfe.groupby(['Wind Speed Category (knots)','dir_binned']).size()\\\n",
    "        .reset_index(name=\"frequency\") #grouping\n",
    "g.reset_index(inplace=True) \n",
    "g['percentage'] = g['frequency']/g['frequency'].sum()\n",
    "g['percentage%'] = g['percentage']*100\n",
    "g = g.replace(r'North', 'N', regex=True)\n",
    "\n",
    "fig = px.bar_polar(g, r=\"percentage%\", theta=\"dir_binned\",\n",
    "                   color=\"Wind Speed Category (knots)\", template=\"plotly_dark\",\n",
    "                   color_discrete_sequence= px.colors.sequential.Plasma_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(wave_df['SignificantWaveHeight (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides a way to look at a univariate distribution. A \n",
    "# univeriate distribution provides a distribution for one variable\n",
    "# Kernal Density Estimation with a Histogram is provided\n",
    "# kde=False removes the KDE\n",
    "# Bins define how many buckets to divide the data up into between intervals\n",
    "# For example put all profits between $10 and $20 in this bucket\n",
    "sns.distplot(crash_df['not_distracted'], kde=False, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointplot compares 2 distributions and plots a scatter plot by default\n",
    "# As we can see as people tend to speed they also tend to drink & drive\n",
    "# With kind you can create a regression line with kind='reg'\n",
    "# You can create a 2D KDE with kind='kde'\n",
    "# Kernal Density Estimation estimates the distribution of data\n",
    "# You can create a hexagon distribution with kind='hex'\n",
    "sns.jointplot(x='speeding', y='alcohol', data=crash_df, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='WindDirection (degrees true)', y='WindSpeed (knots)', data=m2_df, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the KDE plot\n",
    "sns.kdeplot(tide_pred_df['alcohol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(tide_pred_df['Water_Level (metres)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plot plots relationships across the entire data frames numerical values\n",
    "sns.pairplot(crash_df)\n",
    "\n",
    "# Load data on tips\n",
    "tips_df = sns.load_dataset('tips')\n",
    "\n",
    "# With hue you can pass in a categorical column and the charts will be colorized\n",
    "# You can use color maps from Matplotlib to define what colors to use\n",
    "# sns.pairplot(tips_df, hue='sex', palette='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(m2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(m5_df, palette='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rug Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a single column of datapoints in an array as sticks on an axis\n",
    "# With a rug plot you'll see a more dense number of lines where the amount is \n",
    "# most common. This is like how a histogram is taller where values are more common\n",
    "sns.rugplot(tips_df['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.rugplot(wave_df['SignificantWaveHeight (cm)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set styling for your axes and grids\n",
    "# white, darkgrid, whitegrid, dark, ticks\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# You can use figure sizing from Matplotlib\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "# Change size of lables, lines and other elements to best fit\n",
    "# how you will present your data (paper, talk, poster)\n",
    "sns.set_context('paper', font_scale=1.3)\n",
    "\n",
    "sns.jointplot(x='WindDirection (degrees true)', y='WindSpeed (knots)', data=m5_df, kind='hex', palette='Reds')\n",
    "\n",
    "# Get rid of spines\n",
    "# You can turn of specific spines with right=True, left=True\n",
    "# bottom=True, top=True\n",
    "sns.despine(left=False, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on distributions using categorical data in reference to one of the numerical\n",
    "# columns\n",
    "\n",
    "# Aggregate categorical data based on a function (mean is the default)\n",
    "# Estimate total bill amount based on sex\n",
    "# With estimator you can define functions to use other than the mean like those\n",
    "# provided by NumPy : median, std, var, cov or make your own functions\n",
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "sns.barplot(x='year',y='WindSpeed (knots)',data=m5_df, estimator=np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A count plot is like a bar plot, but the estimator is counting \n",
    "# the number of occurances\n",
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "sns.countplot(y='mean_yr_station', data=m5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# A box plot allows you to compare different variables\n",
    "# The box shows the quartiles of the data. The bar in the middle is the median and\n",
    "# the box extends 1 standard deviation from the median\n",
    "# The whiskers extend to all the other data aside from the points that are considered\n",
    "# to be outliers\n",
    "# Hue can add another category being sex\n",
    "# We see men spend way more on Friday versus less than women on Saturday\n",
    "sns.boxplot(x='day',y='total_bill',data=tips_df, hue='sex')\n",
    "\n",
    "# Moves legend to the best position\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot is a combination of the boxplot and KDE\n",
    "# While a box plot corresponds to data points, the violin plot uses the KDE estimation\n",
    "# of the data points\n",
    "# Split allows you to compare how the categories compare to each other\n",
    "sns.violinplot(x='day',y='total_bill',data=tips_df, hue='sex',split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# The strip plot draws a scatter plot representing all data points where one\n",
    "# variable is categorical. It is often used to show all observations with \n",
    "# a box plot that represents the average distribution\n",
    "# Jitter spreads data points out so that they aren't stacked on top of each other\n",
    "# Hue breaks data into men and women\n",
    "# Dodge separates the men and women data\n",
    "sns.stripplot(x='day',y='total_bill',data=tips_df, jitter=True, \n",
    "              hue='sex', dodge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A swarm plot is like a strip plot, but points are adjusted so they don't overlap\n",
    "# It looks like a combination of the violin and strip plots\n",
    "# sns.swarmplot(x='day',y='total_bill',data=tips_df)\n",
    "\n",
    "# You can stack a violin plot with a swarm\n",
    "sns.violinplot(x='day',y='total_bill',data=tips_df)\n",
    "sns.swarmplot(x='day',y='total_bill',data=tips_df, color='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.set_style('dark')\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "# You can use Matplotlibs color maps for color styling\n",
    "# https://matplotlib.org/3.3.1/tutorials/colors/colormaps.html\n",
    "sns.stripplot(x='day',y='total_bill',data=tips_df, hue='sex', \n",
    "             palette='seismic')\n",
    "\n",
    "# Add the optional legend with a location number (best: 0, \n",
    "# upper right: 1, upper left: 2, lower left: 3, lower right: 4,\n",
    "# https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.legend.html)\n",
    "# or supply a tuple of x & y from lower left\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "# To create a heatmap with data you must have data set up as a matrix where variables\n",
    "# are on the columns and rows\n",
    "\n",
    "# Correlation tells you how influential a variable is on the result\n",
    "# So we see that n previous accident is heavily correlated with accidents, while the\n",
    "# insurance premium is not\n",
    "crash_mx = crash_df.corr()\n",
    "\n",
    "# Create the heatmap, add annotations and a color map\n",
    "sns.heatmap(crash_mx, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of Weather Buoy variables\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "# To create a heatmap with data you must have data set up as a matrix where variables\n",
    "# are on the columns and rows\n",
    "\n",
    "m2_mx = m2_df.corr()\n",
    "\n",
    "# Create the heatmap, add annotations and a color map\n",
    "sns.heatmap(m2_mx, annot=True, cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of Wave Buoy variables\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "# To create a heatmap with data you must have data set up as a matrix where variables\n",
    "# are on the columns and rows\n",
    "\n",
    "wave_mx = wave_df.corr()\n",
    "\n",
    "# Create the heatmap, add annotations and a color map\n",
    "sns.heatmap(wave_mx, annot=True, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "# We can create a matrix with an index of month, columns representing years\n",
    "# and the number of passengers for each\n",
    "# We see that flights have increased over time and that most people travel in\n",
    "# July and August\n",
    "flights = sns.load_dataset(\"flights\")\n",
    "flights = flights.pivot_table(index='month', columns='year', values='passengers')\n",
    "# You can separate data with lines\n",
    "sns.heatmap(flights, cmap='Reds', linecolor='white', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table showing temperature over the years by the months at a station\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "# We can create a matrix with an index of month, columns representing years\n",
    "temperature_by_year = m2_df.pivot_table(index='months', columns='year', values='SeaTemperature (degrees_C)')\n",
    "# You can separate data with lines\n",
    "sns.heatmap(temperature_by_year, cmap='OrRd', linecolor='white', linewidth=0.01).set(title='M2 Irish Sea Avg Sea Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table showing wind speed over the years by the months at a station\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "# create a matrix with an index of month, columns representing years\n",
    "wind_by_year = m5_df.pivot_table(index='month', columns='year', values='WindSpeed (knots)')\n",
    "# separate data with lines\n",
    "sns.heatmap(wind_by_year, cmap='plasma', linecolor='white', linewidth=0.0).set(title='Celtic Sea Wind Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table showing temperature over the years by the months at a station\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_context('paper', font_scale=1.3)\n",
    "\n",
    "# create a matrix with an index of month, columns representing years\n",
    "tides = tide_pred_df.pivot_table(index='month', columns='day', values='Water_Level (metres)')\n",
    "# You can separate data with lines\n",
    "sns.heatmap(tides, cmap='cividis', linewidth=0.1).set(title='Howth - Predicted Daily Tide Times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "# A Cluster map is a hierarchically clustered heatmap\n",
    "# The distance between points is calculated, the closest are joined, and this\n",
    "# continues for the next closest (It compares columns / rows of the heatmap)\n",
    "# This is data on iris flowers with data on petal lengths\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "# Return values for species\n",
    "# species = iris.pop(\"species\")\n",
    "# sns.clustermap(iris)\n",
    "\n",
    "# With our flights data we can see that years have been reoriented to place\n",
    "# like data closer together\n",
    "# You can see clusters of data for July & August for the years 59 & 60\n",
    "# standard_scale normalizes the data to focus on the clustering\n",
    "sns.clustermap(flights,cmap=\"Blues\", standard_scale=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PairGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "# You can create a grid of different plots with complete control over what is displayed\n",
    "# Create the empty grid system using the provided data\n",
    "# Colorize based on species\n",
    "# iris_g = sns.PairGrid(iris, hue=\"species\")\n",
    "\n",
    "# Put a scatter plot across the upper, lower and diagonal\n",
    "# iris_g.map(plt.scatter)\n",
    "\n",
    "# Put a histogram on the diagonal \n",
    "# iris_g.map_diag(plt.hist)\n",
    "# And a scatter plot every place else \n",
    "# iris_g.map_offdiag(plt.scatter)\n",
    "\n",
    "# Have different plots in upper, lower and diagonal\n",
    "# iris_g.map_upper(plt.scatter)\n",
    "# iris_g.map_lower(sns.kdeplot)\n",
    "\n",
    "# You can define define variables for x & y for a custom grid\n",
    "iris_g = sns.PairGrid(iris, hue=\"species\",\n",
    "                      x_vars=[\"sepal_length\", \"sepal_width\"],\n",
    "                      y_vars=[\"petal_length\", \"petal_width\"])\n",
    "\n",
    "iris_g.map(plt.scatter)\n",
    "\n",
    "# Add a legend last\n",
    "iris_g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facet Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also print multiple plots in a grid in which you define columns & rows\n",
    "# Get histogram for smokers and non with total bill for lunch & dinner\n",
    "# tips_fg = sns.FacetGrid(tips_df, col='time', row='smoker')\n",
    "\n",
    "# You can pass in attributes for the histogram\n",
    "# tips_fg.map(plt.hist, \"total_bill\", bins=8)\n",
    "\n",
    "# Create a scatter plot with data on total bill & tip (You need to parameters)\n",
    "# tips_fg.map(plt.scatter, \"total_bill\", \"tip\")\n",
    "\n",
    "# We can assign variables to different colors and increase size of grid\n",
    "# Aspect is 1.3 x the size of height\n",
    "# You can change the order of the columns\n",
    "# Define the palette used\n",
    "# tips_fg = sns.FacetGrid(tips_df, col='time', hue='smoker', height=4, aspect=1.3,\n",
    "#                       col_order=['Dinner', 'Lunch'], palette='Set1')\n",
    "# tips_fg.map(plt.scatter, \"total_bill\", \"tip\", edgecolor='w')\n",
    "\n",
    "# # Define size, linewidth and assign a color of white to markers\n",
    "# kws = dict(s=50, linewidth=.5, edgecolor=\"w\")\n",
    "# # Define that we want to assign different markers to smokers and non\n",
    "# tips_fg = sns.FacetGrid(tips_df, col='sex', hue='smoker', height=4, aspect=1.3,\n",
    "#                         hue_order=['Yes','No'], \n",
    "#                         hue_kws=dict(marker=['^', 'v']))\n",
    "# tips_fg.map(plt.scatter, \"total_bill\", \"tip\", **kws)\n",
    "# tips_fg.add_legend()\n",
    "\n",
    "# This dataframe provides scores for different students based on the level\n",
    "# of attention they could provide during testing\n",
    "att_df = sns.load_dataset(\"attention\")\n",
    "# Put each person in their own plot with 5 per line and plot their scores\n",
    "att_fg = sns.FacetGrid(att_df, col='subject', col_wrap=5, height=1.5)\n",
    "att_fg.map(plt.plot, 'solutions', 'score', marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmplot combines regression plots with facet grid\n",
    "tips_df = sns.load_dataset('tips')\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set_context('paper', font_scale=1.4)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# We can plot a regression plot studying whether total bill effects the tip\n",
    "# hue is used to show separation based off of categorical data\n",
    "# We see that males tend to tip slightly more\n",
    "# Define different markers for men and women\n",
    "# You can effect the scatter plot by passing in a dictionary for styling of markers\n",
    "sns.lmplot(x='total_bill', y='tip', hue='sex', data=tips_df, markers=['o', '^'], \n",
    "          scatter_kws={'s': 100, 'linewidth': 0.5, 'edgecolor': 'w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can separate the data into separate columns for day data\n",
    "# sns.lmplot(x='total_bill', y='tip', col='sex', row='time', data=tips_df)\n",
    "tips_df.head()\n",
    "\n",
    "# Makes the fonts more readable\n",
    "sns.set_context('poster', font_scale=1.4)\n",
    "\n",
    "sns.lmplot(x='total_bill', y='tip', data=tips_df, col='day', hue='sex',\n",
    "          height=8, aspect=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# csv = \"..\\data\\ifba.csv\"\n",
    "# df = pd.read_csv(csv)\n",
    "# Theme\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0), 'axes.linewidth':2})\n",
    "palette = sns.color_palette(\"Set2\", 12)# create a grid with a row for each 'Language'\n",
    "g = sns.FacetGrid(m2_df, palette=palette, row=\"year\", hue=\"year\", aspect=9, height=0.8) # map df - Kernel Density Plot of IMDB Score for each Language\n",
    "g.map_dataframe(sns.kdeplot, x=\"WindSpeed (knots)\", fill=True, alpha=1)\n",
    "g.map_dataframe(sns.kdeplot, x=\"WindSpeed (knots)\", color='black')# function to draw labels\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca() #get current axis\n",
    "    ax.text(0, .2, label, color='black', fontsize=13,\n",
    "    ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "# iterate grid to plot labels\n",
    "g.map(label, \"year\")# adjust subplots to create overlap\n",
    "g.fig.subplots_adjust(hspace=-.5)# remove subplot titles\n",
    "g.set_titles(\"\")# remove yticks and set xlabel\n",
    "g.set(yticks=[], xlabel=\"WindSpeed (knots)\")\n",
    "# remove left spine\n",
    "g.despine(left=True)\n",
    "# set title\n",
    "plt.suptitle('M2 Windspeed', y=0.98)\n",
    "plt.savefig('ridgeplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "url = \"https://gist.githubusercontent.com/borgar/31c1e476b8e92a11d7e9/raw/0fae97dab6830ecee185a63c1cee0008f6778ff6/pulsar.csv\"\n",
    "df = pd.read_csv(url, header=None)\n",
    "df = df.stack().reset_index()\n",
    "df.columns = ['idx', 'x', 'y']\n",
    "sns.set_theme(rc={\"axes.facecolor\": (0, 0, 0, 0), 'figure.facecolor':'#000000', 'axes.grid':False})\n",
    "g = sns.FacetGrid(df, row='idx', aspect=50, height=0.4)# Draw the densities in a few steps\n",
    "g.map(sns.lineplot, 'x', 'y', clip_on=False, alpha=1, linewidth=1.5)\n",
    "g.map(plt.fill_between, 'x', 'y', color='#000000')\n",
    "g.map(sns.lineplot, 'x', 'y', clip_on=False, color='#ffffff', lw=2)# Set the subplots to overlap\n",
    "g.fig.subplots_adjust(hspace=-0.95)\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], xticks=[], ylabel=\"\", xlabel=\"\")\n",
    "g.despine(bottom=True, left=True)\n",
    "plt.savefig('joy.png', facecolor='#000000')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
